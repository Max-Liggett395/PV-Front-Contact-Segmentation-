# U-Net Training Configuration for SEM Image Segmentation

# Dataset paths and configuration
dataset:
  images_dir: "data/images"
  labels_dir: "data/masks/npy"
  train_split: 0.70
  val_split: 0.15
  test_split: 0.15
  seed: 42
  # Exclude low-magnification images (2K, 2.5K, 3.5K, 4K, 5K) that confuse the model
  exclude:
    - "ALBSF_A20_AA_4H_2K_11"
    - "ALBSF_A21_DI_4H_2K_11"
    - "ALBSF_A24_Baseline_2K1"
    - "B31_DI_4hr_2.5K_11"
    - "NPERT_C24_AA_4H_5K_11"
    - "NPERT_C24_AA_4H_5K_21"
    - "NPERT_C25_DI_4H_3.5K_11"
    - "TOPCon_sp3221a_es08_AA_4K1"
    - "TOPCon_sp3230a_es08_DI_4K1"
    - "TOPCon_sp3231a_es16_AA_4K1"
    # Anomalous 10K image: no Silver class, 54.5% background
    - "ALBSF_A24_Baseline_10K_21"

# Model architecture
model:
  name: "unet"
  num_classes: 6
  dropout: 0.3
  in_channels: 1  # Grayscale SEM images

# Training hyperparameters
training:
  batch_size: 8
  num_epochs: 1000
  learning_rate: 1.0e-4
  optimizer: "adam"
  weight_decay: 0.0

  num_workers: 8

  # LR scheduler
  scheduler:
    enabled: true
    type: "reduce_on_plateau"
    factor: 0.5
    patience: 10
    min_lr: 1.0e-7
    mode: "min"

  # Early stopping
  early_stopping:
    enabled: true
    patience: 50
    min_delta: 0.0001
    monitor: "val_loss"
    mode: "min"

# Loss function configuration
loss:
  type: "bce_dice"  # Combined CE + Dice for better class-imbalance handling
  class_weights: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0]  # Placeholder; auto-computed at runtime

# Data augmentation (Albumentations)
augmentation:
  train:
    # Morphological augmentations (most effective for SEM per paper)
    gaussian_blur:
      enabled: true
      blur_limit: [3, 7]
      sigma_limit: [0.5, 1.5]
      p: 0.2

    gauss_noise:
      enabled: true
      std_range: [0.012, 0.028]
      p: 0.2

    # Limited geometric augmentations (less effective but included)
    horizontal_flip:
      enabled: true
      p: 0.5

    vertical_flip:
      enabled: true
      p: 0.5

    rotate:
      enabled: true
      limit: 5  # ±5 degrees
      p: 0.3

    # Normalization (always applied)
    normalize:
      mean: [0.0]
      std: [1.0]
      max_pixel_value: 255.0

  val:
    # Validation: normalization only
    normalize:
      mean: [0.0]
      std: [1.0]
      max_pixel_value: 255.0

# Checkpointing
checkpointing:
  save_dir: "checkpoints"
  save_best: true
  save_latest: true
  monitor: "val_loss"
  mode: "min"
  verbose: true

# Logging
logging:
  log_dir: "logs"
  tensorboard: true
  log_every_n_batches: 10
  print_metrics: true

# Device configuration
device:
  auto_detect: true  # Auto-detect CUDA/MPS/CPU
  mixed_precision: true  # AMP float16 — halves GPU memory usage

# Reproducibility
seed: 42

# Class names for visualization
class_names:
  0: "Background"
  1: "Silver (Ag)"
  2: "Glass"
  3: "Silicon (Si)"
  4: "Void"
  5: "Interfacial Void"

# Class colors for visualization (RGB)
class_colors:
  0: [255, 0, 0]      # Red - Background
  1: [0, 255, 0]      # Green - Silver
  2: [0, 0, 255]      # Blue - Glass
  3: [255, 255, 0]    # Yellow - Silicon
  4: [255, 0, 255]    # Magenta - Void
  5: [0, 255, 255]    # Cyan - Interfacial Void
